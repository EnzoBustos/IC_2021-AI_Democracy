{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pipeline Classes","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OePIL8JZ0cOs"},"source":["#Pipeline Classes - AI Democracy\n","\n","This notebook is to implement the classes responsible for the preprocessing pipeline, note that it assumes that you already have passed the text to the TypoParser functions in previous notebooks. All these objects are design to work only with the text (X) and label (y) columns."]},{"cell_type":"markdown","metadata":{"id":"RYzcm-V5K_I7"},"source":["# Importing main librarie"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rlHXhgzc7S21","executionInfo":{"status":"ok","timestamp":1623638481447,"user_tz":180,"elapsed":18879,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}},"outputId":"a21fa7cc-f6d9-4f6d-87e5-733bbc60d8de"},"source":["!pip install -U spacy"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting spacy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/d8/0361bbaf7a1ff56b44dca04dace54c82d63dad7475b7d25ea1baefafafb2/spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8MB)\n","\u001b[K     |████████████████████████████████| 12.8MB 290kB/s \n","\u001b[?25hCollecting thinc<8.1.0,>=8.0.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/e5/6820eccc01d6d8b1d87c3bd021321516af572dcd551e41712913f880f58f/thinc-8.0.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618kB)\n","\u001b[K     |████████████████████████████████| 624kB 41.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n","Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n","Requirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n","Collecting srsly<3.0.0,>=2.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n","\u001b[K     |████████████████████████████████| 460kB 26.0MB/s \n","\u001b[?25hCollecting pathy>=0.3.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/87/5991d87be8ed60beb172b4062dbafef18b32fa559635a8e2b633c2974f85/pathy-0.5.2-py3-none-any.whl (42kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n","\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.4\n","  Downloading https://files.pythonhosted.org/packages/8d/67/d4002a18e26bf29b17ab563ddb55232b445ab6a02f97bf17d1345ff34d3f/spacy_legacy-3.0.5-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Collecting pydantic<1.8.0,>=1.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/fa/d43f31874e1f2a9633e4c025be310f2ce7a8350017579e9e837a62630a7e/pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n","\u001b[K     |████████████████████████████████| 9.1MB 62.2MB/s \n","\u001b[?25hCollecting typer<0.4.0,>=0.3.0\n","  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n","Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n","Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.0.0)\n","Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n","Collecting catalogue<2.1.0,>=2.0.3\n","  Downloading https://files.pythonhosted.org/packages/9c/10/dbc1203a4b1367c7b02fddf08cb2981d9aa3e688d398f587cea0ab9e3bec/catalogue-2.0.4-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n","Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n","Collecting smart-open<4.0.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n","\u001b[K     |████████████████████████████████| 122kB 53.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.1)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Building wheels for collected packages: smart-open\n","  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107107 sha256=ce4fdbbe5bf83128faf9d479ff503ce3c3560f805ed5580dcc80032581596e77\n","  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n","Successfully built smart-open\n","Installing collected packages: pydantic, catalogue, srsly, thinc, smart-open, typer, pathy, spacy-legacy, spacy\n","  Found existing installation: catalogue 1.0.0\n","    Uninstalling catalogue-1.0.0:\n","      Successfully uninstalled catalogue-1.0.0\n","  Found existing installation: srsly 1.0.5\n","    Uninstalling srsly-1.0.5:\n","      Successfully uninstalled srsly-1.0.5\n","  Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Found existing installation: smart-open 5.0.0\n","    Uninstalling smart-open-5.0.0:\n","      Successfully uninstalled smart-open-5.0.0\n","  Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","Successfully installed catalogue-2.0.4 pathy-0.5.2 pydantic-1.7.4 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 thinc-8.0.4 typer-0.3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XuWoEZPr7V1h","executionInfo":{"status":"ok","timestamp":1623638536465,"user_tz":180,"elapsed":55025,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}},"outputId":"d8d62cd9-ca77-4f47-a9e2-777d2dbb79c1"},"source":["!python -m spacy download pt_core_news_lg"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-06-14 02:41:24.496983: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","Collecting pt-core-news-lg==3.0.0\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.0.0/pt_core_news_lg-3.0.0-py3-none-any.whl (578.1MB)\n","\u001b[K     |████████████████████████████████| 578.1MB 27kB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from pt-core-news-lg==3.0.0) (3.0.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (57.0.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (2.23.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (2.0.4)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (0.5.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (20.9)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (2.11.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (3.0.5)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (8.0.4)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (2.0.5)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (1.19.5)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (2.4.1)\n","Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (1.7.4)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (0.4.1)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (3.7.4.3)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (3.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (1.0.5)\n","Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (0.3.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (0.8.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (4.41.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (2020.12.5)\n","Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (3.4.1)\n","Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (3.0.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (2.4.7)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (2.0.1)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->pt-core-news-lg==3.0.0) (7.1.2)\n","Installing collected packages: pt-core-news-lg\n","Successfully installed pt-core-news-lg-3.0.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('pt_core_news_lg')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NnE5ZNrmK-sp"},"source":["import pandas as pd\n","import re\n","import nltk\n","import numpy as np\n","import pickle\n","import spacy\n","from gensim.test.utils import common_texts\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from gensim.models import Word2Vec, KeyedVectors"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QnYH7GNdLFI1"},"source":["# Loading the Data"]},{"cell_type":"code","metadata":{"id":"2s344co0LEiD"},"source":["with open('no_typos (4).pkl', 'rb') as f:\n","    df = pickle.load(f)\n","\n","X = df['Text']\n","\n","#I don't have the classification yet, so\n","#y = df['classification'] #Binary 0 - interrupt; 1 - continuity"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sUCVVx9MNRJD"},"source":["# Tokenizer"]},{"cell_type":"code","metadata":{"id":"2SPcd-e3NTnk"},"source":["class CustomTokenizer():\n","    \n","    def __init__(self, mappers='', custom_specials='default'):\n","        if custom_specials == 'default':\n","            self.custom_specials = \"!\\\"#$%&'()*+,¸./:;<=>?@[\\]^_`{|}-–⎯—«»´°‘’…~ªº€0123456789\"\n","        else:\n","            self.custom_specials = custom_specials\n","        \n","        if mappers:\n","            with open(mappers, 'rb') as f:\n","                mappers = pickle.load(f)\n","                self.person_map = mappers[0]\n","                self.party_map = mappers[1]\n","    \n","    #Find the Names and Parties of politicians and make them as a unique token\n","    #Ex.: \"Inês de Sousa Real\" --> [\"Inês de Sousa Real\"], not [\"Inês\", \"de\", \"Sousa\", \"Real\"]\n","    def fit(self, dataframe):\n","        person_mapper = {}\n","        for person in pd.Series(dataframe['Person'].unique()).to_list():\n","            person_mapper[''.join(person.lower().split())] = person\n","        \n","        party_mapper = {}\n","        for party in pd.Series(dataframe['Party'].unique()).to_list():\n","            party = str(party)\n","            party_mapper[''.join(party.lower().split())] = party\n","        \n","        mappers = (person_mapper, party_mapper)\n","\n","        self.person_map = person_mapper\n","        self.party_map = party_mapper\n","\n","        with open('mappers.pkl', 'wb') as f:\n","            pickle.dump(mappers, f)\n","\n","    def remove_specials_chars(self, text):\n","        for special_char in self.custom_specials:\n","            text = text.replace(special_char, ' ')\n","        text = text.replace('CDS PP', 'CDS-PP')\n","        return text\n","    \n","    #Apply the mapper, so a name becomes a single concatenated lowered string\n","    #ex.: \"Inês de Sousa Real\" --> \"inesdesousareal\"\n","    def apply_mappers(self, text):\n","\n","        for person in self.person_map:\n","             text = text.replace(self.person_map[person], person)\n","\n","        for party in self.party_map:\n","            party = str(party)\n","            text = text.replace(self.party_map[party], party)\n","        \n","        return text\n","\n","    def convert_text(self, text):\n","        #converts to lowercase and split the words\n","        text = text.lower()\n","        words = text.split()\n","        \n","        return words\n","    \n","    def transform(self, X):\n","        X = X.apply(self.remove_specials_chars)\n","        X = X.apply(self.apply_mappers)\n","        X = X.apply(self.convert_text)\n","        return X\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vRX0XTsiNQZG"},"source":["tokenizer = CustomTokenizer()\n","tokenizer.fit(df)\n","X = tokenizer.transform(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wOEHSrwh4PxD","executionInfo":{"status":"ok","timestamp":1623638543676,"user_tz":180,"elapsed":25,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}},"outputId":"85ba0f1f-6c1f-4923-9a51-3b4d7300000b"},"source":["X[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['dirijo',\n"," 'um',\n"," 'abraço',\n"," 'a',\n"," 'todos',\n"," 'neste',\n"," 'regresso',\n"," 'dos',\n"," 'plenários',\n"," 'à',\n"," 'casa',\n"," 'da',\n"," 'democracia',\n"," 'esperávamos',\n"," 'que',\n"," 'nesta',\n"," 'altura',\n"," 'já',\n"," 'pudéssemos',\n"," 'ter',\n"," 'regras',\n"," 'mais',\n"," 'flexíveis',\n"," 'mas',\n"," 'infelizmente',\n"," 'os',\n"," 'números',\n"," 'e',\n"," 'as',\n"," 'consequências',\n"," 'concretas',\n"," 'não',\n"," 'nos',\n"," 'permitem',\n"," 'tal',\n"," 'e',\n"," 'portanto',\n"," 'continuamos',\n"," 'no',\n"," 'essencial',\n"," 'com',\n"," 'as',\n"," 'regras',\n"," 'que',\n"," 'presidiram',\n"," 'aos',\n"," 'últimos',\n"," 'plenários',\n"," 'da',\n"," 'sessão',\n"," 'legislativa',\n"," 'srs',\n"," 'deputados',\n"," 'da',\n"," 'nossa',\n"," 'ordem',\n"," 'do',\n"," 'dia',\n"," 'constam',\n"," 'declarações',\n"," 'políticas',\n"," 'porém',\n"," 'antes',\n"," 'disso',\n"," 'a',\n"," 'sr',\n"," 'secretária',\n"," 'mariadaluzrosinha',\n"," 'fará',\n"," 'o',\n"," 'favor',\n"," 'de',\n"," 'anunciar',\n"," 'a',\n"," 'entrada',\n"," 'de',\n"," 'algumas',\n"," 'iniciativas',\n"," 'tem',\n"," 'a',\n"," 'palavra',\n"," 'sr',\n"," 'secretária']"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"j2Y65MQo0Wyx"},"source":["# Stopwords"]},{"cell_type":"code","metadata":{"id":"8a5K2qJfp2tk"},"source":["class StopwordsParser():\n","\n","    def __init__(self, stopwords_file=''):\n","        self.stopwords = open(stopwords_file, 'r').read().splitlines()\n","        \n","    def fit(self):\n","        pass\n","\n","    def remove_stopwords(self, text):\n","        text = [token for token in text if token not in self.stopwords]\n","        return text\n","\n","    def transform(self, X):\n","        X = X.apply(self.remove_stopwords)\n","        return X\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JnFnoPgAkiVJ"},"source":["stopwords_parser = StopwordsParser('complete_stopwords_set.txt')\n","X = stopwords_parser.transform(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A-SUirNB1qze","executionInfo":{"status":"ok","timestamp":1623638780256,"user_tz":180,"elapsed":24,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}},"outputId":"474430d4-9882-4c72-f870-b4e0ac7d4d9f"},"source":["X[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['dirijo',\n"," 'abraço',\n"," 'todos',\n"," 'neste',\n"," 'regresso',\n"," 'plenários',\n"," 'casa',\n"," 'democracia',\n"," 'esperávamos',\n"," 'nesta',\n"," 'altura',\n"," 'pudéssemos',\n"," 'ter',\n"," 'regras',\n"," 'flexíveis',\n"," 'infelizmente',\n"," 'números',\n"," 'consequências',\n"," 'concretas',\n"," 'permitem',\n"," 'tal',\n"," 'portanto',\n"," 'continuamos',\n"," 'essencial',\n"," 'regras',\n"," 'últimos',\n"," 'plenários',\n"," 'sessão',\n"," 'legislativa',\n"," 'ordem',\n"," 'dia',\n"," 'constam',\n"," 'declarações',\n"," 'políticas',\n"," 'porém',\n"," 'antes',\n"," 'disso',\n"," 'secretária',\n"," 'mariadaluzrosinha',\n"," 'fará',\n"," 'favor',\n"," 'anunciar',\n"," 'entrada',\n"," 'algumas',\n"," 'iniciativas',\n"," 'palavra',\n"," 'secretária']"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"BJlc_J5_4eWY"},"source":["# Lemmatizer"]},{"cell_type":"code","metadata":{"id":"0F_Fg7o74f3c"},"source":["class CustomLemmatizer():\n","    def __init__(self, mappers=''):\n","        self.nlp = spacy.load('pt_core_news_lg',\n","                              exclude=['attribute_ruler', 'tok2vec', 'morphologizer',\n","                                       'parser', 'senter', 'ner', 'attribute_ruler'])\n","        self.nlp.max_length = 6136000\n","\n","        if mappers:\n","            with open(mappers, 'rb') as f:\n","                mappers = pickle.load(f)\n","                self.person_map = mappers[0]\n","                self.party_map = mappers[1]\n","\n","    def fit(self):\n","        pass\n","    \n","    def undo_mapping(self, tokens):\n","        #Deixando nomes de pessoas como tokens legiveis novamente\n","        for i, word in enumerate(tokens):\n","            if word in self.person_map:\n","                tokens[i] = self.person_map[word]\n","            elif word in self.party_map:\n","                tokens[i] = self.party_map[word]\n","        return tokens\n","    \n","    def normalize_tokens(self, tokens):\n","        meaningful_string = ' '.join(tokens)\n","        spacy_object = self.nlp(meaningful_string)\n","        normalized_tokens = [token.lemma_ for token in spacy_object]\n","        return normalized_tokens\n","\n","    def transform(self, X):\n","        X = X.apply(self.normalize_tokens)\n","        X = X.apply(self.undo_mapping)\n","        return X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EUkXGpAT4c-a"},"source":["lemmatizer = CustomLemmatizer('mappers.pkl')\n","X = lemmatizer.transform(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T2-UpxG6GQDN","executionInfo":{"status":"ok","timestamp":1623638788357,"user_tz":180,"elapsed":16,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}},"outputId":"22fb9bbd-64fa-4af6-e80e-9d4addc6126c"},"source":["X[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['dirigir',\n"," 'abraçar',\n"," 'todo',\n"," 'neste',\n"," 'regressar',\n"," 'plenário',\n"," 'casar',\n"," 'democracia',\n"," 'esperar',\n"," 'nesta',\n"," 'altura',\n"," 'poder',\n"," 'ter',\n"," 'regrar',\n"," 'flexível',\n"," 'infelizmente',\n"," 'número',\n"," 'consequência',\n"," 'concreto',\n"," 'permitir',\n"," 'tal',\n"," 'portanto',\n"," 'continuar',\n"," 'essencial',\n"," 'regrar',\n"," 'último',\n"," 'plenário',\n"," 'sessão',\n"," 'legislativo',\n"," 'ordem',\n"," 'dia',\n"," 'constar',\n"," 'declaração',\n"," 'político',\n"," 'porém',\n"," 'antar',\n"," 'disso',\n"," 'Secretário',\n"," 'Maria da Luz Rosinha',\n"," 'fazer',\n"," 'favor',\n"," 'anunciar',\n"," 'entrar',\n"," 'algum',\n"," 'iniciativo',\n"," 'palavra',\n"," 'Secretário']"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"XE6S50C4F_86"},"source":["#Word2Vec"]},{"cell_type":"code","metadata":{"id":"Feb1oT594Yph","executionInfo":{"status":"ok","timestamp":1623702520127,"user_tz":180,"elapsed":1363,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}}},"source":["import pandas as pd\n","import numpy as np\n","import pickle\n","from gensim.test.utils import common_texts\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from gensim.models import Word2Vec, KeyedVectors"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"znwSHE134ZyH","executionInfo":{"status":"ok","timestamp":1623702522703,"user_tz":180,"elapsed":2579,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}}},"source":["df = pd.read_excel('with_clean_texts.xlsx')\n","df.replace('nan', np.nan, inplace=True)\n","X = df['Normalized_Tokens']\n","\n","df['Text'] = X\n","data_mask = ~pd.isna(df['Y_true'])\n","data = df[data_mask].copy()\n","data = data.reset_index(drop=True)\n","\n","X_new = data['Text'].to_list()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWT2_CblGCf_","executionInfo":{"status":"ok","timestamp":1623702674134,"user_tz":180,"elapsed":151433,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}}},"source":["sentences_ = X\n","w2v_10 = Word2Vec(sentences=sentences_, size=10, min_count=1, sg=1)\n","w2v_50 = Word2Vec(sentences=sentences_, size=50, min_count=1, sg=1)\n","w2v_100 = Word2Vec(sentences=sentences_, size=100, min_count=1, sg=1)\n","w2v_300 = Word2Vec(sentences=sentences_, size=300, min_count=1, sg=1)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"yGApR-FoHBHq","executionInfo":{"status":"ok","timestamp":1623702675393,"user_tz":180,"elapsed":1266,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}}},"source":["X_10 = []\n","X_50 = []\n","X_100 = []\n","X_300 = []\n","\n","for sentence in X_new:\n","    act_sent_10 = []\n","    act_sent_50 = []\n","    act_sent_100 = []\n","    act_sent_300 = []\n","    for word in sentence:\n","        act_sent_10.append(w2v_10.wv[word])\n","        act_sent_50.append(w2v_50.wv[word])\n","        act_sent_100.append(w2v_100.wv[word])\n","        act_sent_300.append(w2v_300.wv[word])\n","    if len(act_sent_10) > 0:\n","        stack_10 = np.stack(act_sent_10)\n","        X_10.append(np.median(stack_10, axis=0))\n","    else:\n","        X_10.append(np.zeros(10))\n","    if len(act_sent_50) > 0:\n","        stack_50 = np.stack(act_sent_50)\n","        X_50.append(np.median(stack_50, axis=0))\n","    else:\n","        X_50.append(np.zeros(50))\n","    if len(act_sent_100) > 0:\n","        stack_100 = np.stack(act_sent_100)\n","        X_100.append(np.median(stack_100, axis=0))\n","    else:\n","        X_100.append(np.zeros(100))\n","    if len(act_sent_300) > 0:\n","        stack_300 = np.stack(act_sent_300)\n","        X_300.append(np.median(stack_300, axis=0))\n","    else:\n","        X_300.append(np.zeros(300))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"sNcG2ZEpIxG5","executionInfo":{"status":"ok","timestamp":1623702675394,"user_tz":180,"elapsed":8,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}}},"source":["with open('X_10.pkl', 'wb') as f:\n","        pickle.dump(X_10, f)\n","with open('X_50.pkl', 'wb') as f:\n","        pickle.dump(X_50, f)\n","with open('X_100.pkl', 'wb') as f:\n","        pickle.dump(X_100, f)\n","with open('X_300.pkl', 'wb') as f:\n","        pickle.dump(X_300, f)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"utKcfhGLkGh_"},"source":["# Embeddings:"]},{"cell_type":"code","metadata":{"id":"_WNfSr6gkBGE","executionInfo":{"status":"ok","timestamp":1623702675396,"user_tz":180,"elapsed":8,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}}},"source":["class CustomEmbeddings():\n","    def __init__(self, model='', vector_size=100, window_size=2):\n","        if model:\n","            self.model = KeyedVectors.load_word2vec_format(model)\n","        self.vector_size = vector_size\n","        self.window_size = window_size\n","\n","    #If no model was given, then apply doc2vec as default\n","    def fit(self, X):\n","        documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X)]\n","        self.model = Doc2Vec(\n","            documents=documents,\n","            vector_size=self.vector_size,\n","            window=self.window_size,\n","            min_count=1\n","        )\n","\n","    def save_model(self, document_name):\n","        self.model.save(document_name)\n","\n","    def transform(self, X):\n","        X = X.apply(self.model.infer_vector)\n","        return X"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"1vHqSZysQ_WZ","executionInfo":{"status":"ok","timestamp":1623702762360,"user_tz":180,"elapsed":86971,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}}},"source":["documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X)]\n","\n","d2v_10 = Doc2Vec(documents=documents, \n","                  vector_size=10,\n","                  min_count=1)\n","d2v_50 = Doc2Vec(documents=documents, \n","                  vector_size=50,\n","                  min_count=1)\n","d2v_100 = Doc2Vec(documents=documents, \n","                  vector_size=100,\n","                  min_count=1)\n","d2v_300 = Doc2Vec(documents=documents, \n","                  vector_size=300,\n","                  min_count=1)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"fr9UB4qqThj-","executionInfo":{"status":"ok","timestamp":1623702763788,"user_tz":180,"elapsed":1441,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}}},"source":["X_d2v_10 = np.stack(pd.Series(X_new).apply(d2v_10.infer_vector).to_numpy())\n","X_d2v_50 = np.stack(pd.Series(X_new).apply(d2v_50.infer_vector).to_numpy())\n","X_d2v_100 = np.stack(pd.Series(X_new).apply(d2v_100.infer_vector).to_numpy())\n","X_d2v_300 = np.stack(pd.Series(X_new).apply(d2v_300.infer_vector).to_numpy())"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"rWF-fkwURsAP","executionInfo":{"status":"ok","timestamp":1623702763789,"user_tz":180,"elapsed":8,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}}},"source":["with open('X_d2v_10.pkl', 'wb') as f:\n","        pickle.dump(X_d2v_10, f)\n","with open('X_d2v_50.pkl', 'wb') as f:\n","        pickle.dump(X_d2v_50, f)\n","with open('X_d2v_100.pkl', 'wb') as f:\n","        pickle.dump(X_d2v_100, f)\n","with open('X_d2v_300.pkl', 'wb') as f:\n","        pickle.dump(X_d2v_300, f)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"4mQNzfAjNkfd","executionInfo":{"status":"ok","timestamp":1623702859603,"user_tz":180,"elapsed":293,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}},"outputId":"2f19ab0d-c81b-484a-b1c1-c0aed70abeb7"},"source":["X_new[0]"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"['obrigar', 'Secretária', 'Maria', 'da', 'Luz', 'Rosinha', 'pois', 'condição', 'iniciar', 'primeiro', 'pontar', 'agendar', 'consistir', 'declaração', 'político', 'primeiro', 'declaração', 'político', 'caber', 'grupar', 'parlamentar', 'PS', 'antar', 'dar', 'palavra', 'Luís', 'Moreira', 'Testa', 'relembrar', 'regrar', 'funcionamento', 'plenário', 'continuar', 'mesmo', 'vigor', 'antar', 'féria', 'infelizmente', 'realidade', 'fazer', 'favor']\""]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mWJIYo4WNms1","executionInfo":{"status":"ok","timestamp":1623702861443,"user_tz":180,"elapsed":223,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}},"outputId":"b6ff0e1b-413b-4bbf-89d7-8c42b39b900a"},"source":["d2v_10.infer_vector(X_new[0])"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.44160825, -0.04035217, -0.18447252,  0.2545964 ,  0.19554137,\n","        0.28900757,  0.13697784, -0.03406145, -0.2350337 ,  0.05136514],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"q6HvAIURO42D","executionInfo":{"status":"error","timestamp":1623704400704,"user_tz":180,"elapsed":229,"user":{"displayName":"Enzo Bustos da Silva","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipjzEo8ZMU7T5CScvwquuNadVZOv9a7EefCtELMQ=s64","userId":"00423683093258305256"}},"outputId":"aaaee8d8-c22c-4dcb-fc27-672f16be55e5"},"source":["d2v_10.wv[X_new[0]]"],"execution_count":22,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-5a33fb78b243>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md2v_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"word '['obrigar', 'Secretária', 'Maria', 'da', 'Luz', 'Rosinha', 'pois', 'condição', 'iniciar', 'primeiro', 'pontar', 'agendar', 'consistir', 'declaração', 'político', 'primeiro', 'declaração', 'político', 'caber', 'grupar', 'parlamentar', 'PS', 'antar', 'dar', 'palavra', 'Luís', 'Moreira', 'Testa', 'relembrar', 'regrar', 'funcionamento', 'plenário', 'continuar', 'mesmo', 'vigor', 'antar', 'féria', 'infelizmente', 'realidade', 'fazer', 'favor']' not in vocabulary\""]}]}]}